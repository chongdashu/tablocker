name: Deploy - Backend and Frontend

on:
  pull_request:
    branches:
      - main
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      branch:
        description: "Branch to deploy"
        required: true
        default: "main"

jobs:
  deploy-backend:
    name: Deploy Backend to Environment
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_DEFAULT_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build, tag, and push backend image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY_BACKEND }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG ./backend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

      - name: Build, tag, and push frontend image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY_FRONTEND }}
          IMAGE_TAG: ${{ github.sha }}
          NODE_ENV: production
          NEXT_PUBLIC_POSTHOG_KEY: ${{ secrets.NEXT_PUBLIC_POSTHOG_KEY }}
          NEXT_PUBLIC_POSTHOG_HOST: ${{ secrets.NEXT_PUBLIC_POSTHOG_HOST }}
        run: |
          docker build \
            --build-arg NODE_ENV=${NODE_ENV} \
            --build-arg NEXT_PUBLIC_POSTHOG_KEY=${NEXT_PUBLIC_POSTHOG_KEY} \
            --build-arg NEXT_PUBLIC_POSTHOG_HOST=${NEXT_PUBLIC_POSTHOG_HOST} \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG ./frontend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

      - name: Check and prune disk space on EC2
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          AWS_HOST: ${{ secrets.AWS_HOST }}
          AWS_USER: ${{ secrets.AWS_USER }}
        run: |
          echo "$PRIVATE_KEY" > private_key && chmod 600 private_key
          ssh -o StrictHostKeyChecking=no -i private_key ${AWS_USER}@${AWS_HOST} '
            AVAILABLE_SPACE=$(df --output=avail / | tail -n1)
            MIN_REQUIRED_SPACE=2097152 # 2GB in KB
            if [ "$AVAILABLE_SPACE" -lt "$MIN_REQUIRED_SPACE" ]; then
              echo "Not enough disk space. Pruning Docker resources..."
              docker system prune -f -a
              AVAILABLE_SPACE_AFTER_PRUNE=$(df --output=avail / | tail -n1)
              if [ "$AVAILABLE_SPACE_AFTER_PRUNE" -lt "$MIN_REQUIRED_SPACE" ]; then
                echo "Error: Still not enough disk space after pruning. At least 2GB is required."
                exit 1
              fi
            fi
          '

      - name: Copy docker-compose.yml and nginx configurations to EC2
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          AWS_HOST: ${{ secrets.AWS_HOST }}
          AWS_USER: ${{ secrets.AWS_USER }}
          PROJECT_ROOT: /home/${{ secrets.AWS_USER }}/untab
        run: |
          echo "$PRIVATE_KEY" > private_key && chmod 600 private_key
          ssh -o StrictHostKeyChecking=no -i private_key $AWS_USER@$AWS_HOST "mkdir -p $PROJECT_ROOT"
          scp -o StrictHostKeyChecking=no -i private_key docker-compose.yml $AWS_USER@$AWS_HOST:$PROJECT_ROOT/docker-compose.yml
          scp -o StrictHostKeyChecking=no -i private_key nginx.conf $AWS_USER@$AWS_HOST:$PROJECT_ROOT/nginx.conf
          scp -o StrictHostKeyChecking=no -i private_key default.conf $AWS_USER@$AWS_HOST:$PROJECT_ROOT/default.conf

      - name: Deploy to EC2
        env:
          PRIVATE_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
          AWS_HOST: ${{ secrets.AWS_HOST }}
          AWS_USER: ${{ secrets.AWS_USER }}
          PROJECT_ROOT: /home/${{ secrets.AWS_USER }}/untab
        run: |
          echo "$PRIVATE_KEY" > private_key && chmod 600 private_key
          ssh -o StrictHostKeyChecking=no -i private_key ${AWS_USER}@${AWS_HOST} '
            cd ${{ env.PROJECT_ROOT }} || mkdir -p ${{ env.PROJECT_ROOT }} && cd ${{ env.PROJECT_ROOT }};

            echo "Setting AWS environment variables..."
            export AWS_ACCESS_KEY_ID=${{secrets.AWS_ACCESS_KEY_ID}}
            export AWS_SECRET_ACCESS_KEY=${{secrets.AWS_SECRET_ACCESS_KEY}}
            export AWS_DEFAULT_REGION=${{secrets.AWS_DEFAULT_REGION}}

            echo "Logging into AWS ECR..."
            aws ecr get-login-password --region ${{ secrets.AWS_DEFAULT_REGION }} | docker login --username AWS --password-stdin  ${{ steps.login-ecr.outputs.registry }}

            echo "Stopping and removing existing containers..."
            docker-compose down || true

            # Wait for containers to be removed
            for i in {1..5}; do
              if [ "$(docker ps -aq -f name=untab-frontend-1)" ] || [ "$(docker ps -aq -f name=untab-backend-1)" ]; then
                echo "Waiting for containers to be removed..."
                sleep 1
              else
                break
              fi
            done

            echo "Starting new containers with updated environment variables..."

            SUPABASE_URL=${{ secrets.SUPABASE_URL }} \
            SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY }} \
            SUPABASE_JWT_PUBLIC_KEY=${{ secrets.SUPABASE_JWT_PUBLIC_KEY }} \
            STRIPE_PUBLISHABLE_KEY=${{ secrets.STRIPE_PUBLISHABLE_KEY }} \
            STRIPE_SECRET_KEY=${{ secrets.STRIPE_SECRET_KEY }} \
            STRIPE_WEBHOOK_SECRET=${{ secrets.STRIPE_WEBHOOK_SECRET }} \
            STRIPE_UNTAB_PRICE_ID=${{ secrets.STRIPE_UNTAB_PRICE_ID }} \
            ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }} \
            ECR_REPOSITORY_BACKEND=${{ secrets.ECR_REPOSITORY_BACKEND }} \
            ECR_REPOSITORY_FRONTEND=${{ secrets.ECR_REPOSITORY_FRONTEND }} \
            IMAGE_TAG=${{ github.sha }} \
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            AWS_DEFAULT_REGION=${{ secrets.AWS_DEFAULT_REGION }} \
            POSTGRES_DATABASE_URL=${{ secrets.POSTGRES_DATABASE_URL }} \
            NEXT_PUBLIC_POSTHOG_KEY=${{ secrets.NEXT_PUBLIC_POSTHOG_KEY }} \
            NEXT_PUBLIC_POSTHOG_HOST=${{ secrets.NEXT_PUBLIC_POSTHOG_HOST }} \
            docker-compose up -d
          '
          rm private_key

      - name: Verify External Accessibility - Backend API
        run: |

          echo "Waiting for FastAPI server to start..."
          echo "Verifying external accessibility..."

          max_attempts=15
          attempt=1

          while [ $attempt -le $max_attempts ]; do
            if curl -sSf https://untab.xyz/api/health/check > /dev/null 2>&1; then
              echo "External HTTPS accessibility verified successfully!"
              exit 0
            else
              echo "Attempt $attempt: Failed to verify external accessibility. Retrying in 2 seconds..."
              sleep 2
              attempt=$((attempt + 1))
            fi
          done

          echo "Failed to verify external accessibility after 30 seconds"
          exit 1

      - name: Verify External Accessibility - Frontend Website
        run: |
          echo "Verifying external accessibility..."
          if curl -sSf -o /dev/null -w "%{http_code}" https://untab.xyz | grep -q 200; then
            echo "External HTTPS accessibility verified successfully!"
          else
            echo "Failed to verify external accessibility. HTTP status code: $(curl -sSf -o /dev/null -w "%{http_code}" https://untab.xyz)"
            exit 1
          fi
